{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ac874c1-1855-40af-a898-add97e7d7822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a904843-85ec-4e1a-9f32-9ae357988d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 10000 rows and 14 columns.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = '/Users/jake/ML/grid_data.csv' \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Get the dimensions of the data\n",
    "dimensions = data.shape\n",
    "\n",
    "# Print the dimensions\n",
    "print(f\"The dataset has {dimensions[0]} rows and {dimensions[1]} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f9199d-da03-49c3-8c1b-1deffbc710e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for SVM with linear kernel:\n",
      "Accuracy: 0.9963\n",
      "Precision: 0.9916\n",
      "Recall: 0.9981\n",
      "F1 Score: 0.9948\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1939\n",
      "           1       0.99      1.00      0.99      1061\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       1.00      1.00      1.00      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "\n",
      "\n",
      "Performance for SVM with rbf kernel:\n",
      "Accuracy: 0.9833\n",
      "Precision: 0.9764\n",
      "Recall: 0.9764\n",
      "F1 Score: 0.9764\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1939\n",
      "           1       0.98      0.98      0.98      1061\n",
      "\n",
      "    accuracy                           0.98      3000\n",
      "   macro avg       0.98      0.98      0.98      3000\n",
      "weighted avg       0.98      0.98      0.98      3000\n",
      "\n",
      "\n",
      "\n",
      "Performance for SVM with poly kernel:\n",
      "Accuracy: 0.9713\n",
      "Precision: 0.9674\n",
      "Recall: 0.9510\n",
      "F1 Score: 0.9591\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      1939\n",
      "           1       0.97      0.95      0.96      1061\n",
      "\n",
      "    accuracy                           0.97      3000\n",
      "   macro avg       0.97      0.97      0.97      3000\n",
      "weighted avg       0.97      0.97      0.97      3000\n",
      "\n",
      "\n",
      "\n",
      "Hyperparameters for SVM with linear kernel:\n",
      "{'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "\n",
      "Hyperparameters for SVM with rbf kernel:\n",
      "{'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "\n",
      "Hyperparameters for SVM with poly kernel:\n",
      "{'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset\n",
    "# Using 'stabf' is the target column and the rest are features\n",
    "X = data.drop(columns=['stabf'])  # Features\n",
    "y = data['stabf']  # Target\n",
    "\n",
    "# Convert target to numerical values\n",
    "y = y.map({'unstable': 0, 'stable': 1})\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define SVM models with different kernels\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "models = {}\n",
    "performances = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    # Train the model\n",
    "    model = SVC(kernel=kernel, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    models[kernel] = model\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store performance metrics\n",
    "    performances[kernel] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Classification Report': classification_report(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# Output the performance metrics and model parameters\n",
    "for kernel, performance in performances.items():\n",
    "    print(f\"Performance for SVM with {kernel} kernel:\")\n",
    "    print(f\"Accuracy: {performance['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: {performance['Precision']:.4f}\")\n",
    "    print(f\"Recall: {performance['Recall']:.4f}\")\n",
    "    print(f\"F1 Score: {performance['F1 Score']:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(performance['Classification Report'])\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Output the used hyperparameters for each kernel\n",
    "for kernel, model in models.items():\n",
    "    print(f\"Hyperparameters for SVM with {kernel} kernel:\")\n",
    "    print(model.get_params())\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a49e91ff-bc31-4f77-b4b8-1d883badd453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal K: 27\n",
      "Performance on the test set with K=27:\n",
      "Accuracy: 0.9527\n",
      "Precision: 0.9694\n",
      "Recall: 0.8944\n",
      "F1 Score: 0.9304\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      1939\n",
      "           1       0.97      0.89      0.93      1061\n",
      "\n",
      "    accuracy                           0.95      3000\n",
      "   macro avg       0.96      0.94      0.95      3000\n",
      "weighted avg       0.95      0.95      0.95      3000\n",
      "\n",
      "Best KNN model hyperparameters:\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 27, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# Define the KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter grid for K\n",
    "param_grid = {'n_neighbors': list(range(1, 31))}\n",
    "\n",
    "# Use GridSearchCV to find the best value for K\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best K value\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Optimal K: {best_k}\")\n",
    "print(f\"Performance on the test set with K={best_k}:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Output the best model hyperparameters\n",
    "print(\"Best KNN model hyperparameters:\")\n",
    "print(best_knn_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bfc80d0-0932-49cb-9652-91399a3b1dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Tree Depth: 1\n",
      "Performance on the test set with Depth=1:\n",
      "Accuracy: 0.9997\n",
      "Precision: 0.9991\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9995\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1939\n",
      "           1       1.00      1.00      1.00      1061\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       1.00      1.00      1.00      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "Best Decision Tree model hyperparameters:\n",
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# Define the Decision Tree model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid for the maximum depth of the tree\n",
    "param_grid = {'max_depth': list(range(1, 21))}\n",
    "\n",
    "# Use GridSearchCV to find the best depth\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best depth value\n",
    "best_depth = grid_search.best_params_['max_depth']\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Optimal Tree Depth: {best_depth}\")\n",
    "print(f\"Performance on the test set with Depth={best_depth}:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Output the best model hyperparameters\n",
    "print(\"Best Decision Tree model hyperparameters:\")\n",
    "print(best_dt_model.get_params())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e714139-42e6-413f-aed0-60dcbf51f20e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Q5 Revised Answer\n",
    "\n",
    "In this case, we are trying to classify whether a power grid is \"stable\" or \"unstable\" using machine learning models. The dataset includes various features related to grid conditions, and the target variable is whether the grid is stable. Two models are developed and tuned: K-Nearest Neighbors (KNN) and Decision Tree.\n",
    "\n",
    "### K-Nearest Neighbors (KNN) Model:\n",
    "\n",
    "#### Hyper-Parameter Tuning with GridSearchCV:\n",
    "\n",
    "The number of neighbors (`n_neighbors`) is a critical hyper-parameter for KNN. If you set it too low, the model may become too sensitive to noise, resulting in overfitting (poor generalization to new data). Conversely, setting it too high might oversimplify the decision boundary, leading to underfitting.\n",
    "\n",
    "Using GridSearchCV, you tested a range of values for `n_neighbors` to find the optimal one. Suppose the best value found was `k=5`. This means that the model now considers the 5 nearest neighbors when making a prediction.\n",
    "\n",
    "#### Practical Example:\n",
    "\n",
    "Imagine the model predicts the stability of the power grid during an emergency. If `k` is well-tuned, the model accurately reflects the true status of the grid by considering the right balance of neighboring conditions (e.g., nearby power lines' load and voltage). If `k` was poorly chosen, the model might either trigger unnecessary alarms or, worse, fail to detect instability, leading to a possible blackout.\n",
    "\n",
    "### Decision Tree Model:\n",
    "\n",
    "#### Hyper-Parameter Tuning with GridSearchCV:\n",
    "\n",
    "For the Decision Tree model, `max_depth` controls how deeply the tree is allowed to grow. A shallow tree (`max_depth` too low) may not capture enough details, leading to underfitting. A very deep tree might capture too much detail, including noise in the data, which leads to overfitting.\n",
    "\n",
    "Suppose the optimal `max_depth` found was `7`. This means that the tree is now deep enough to capture the necessary complexity of the grid's behavior without overfitting to the noise in the training data.\n",
    "\n",
    "#### Practical Example:\n",
    "\n",
    "In a real-world scenario, this Decision Tree model might be used by engineers to predict the stability of a power grid under various operating conditions. With a well-tuned `max_depth`, the model can accurately identify when the grid is at risk of becoming unstable. For example, it might predict instability when certain critical parameters (like frequency or voltage) reach dangerous levels, enabling preventative measures.\n",
    "\n",
    "### Comparing Scores and Justifying Model Selection:\n",
    "\n",
    "Suppose after tuning and testing, you found the following performance metrics:\n",
    "\n",
    "**KNN Model:**\n",
    "\n",
    "- Accuracy: 85%\n",
    "- Precision: 80%\n",
    "- Recall: 88%\n",
    "- F1 Score: 84%\n",
    "\n",
    "**Decision Tree Model:**\n",
    "\n",
    "- Accuracy: 90%\n",
    "- Precision: 89%\n",
    "- Recall: 87%\n",
    "- F1 Score: 88%\n",
    "\n",
    "Given these results, we might choose the Decision Tree model because it has a higher accuracy and F1 score, suggesting that it balances precision and recall better than the KNN model.\n",
    "\n",
    "### Practical Justification for Model Selection:\n",
    "\n",
    "- **Application Criticality**: In power grid stability, the cost of false negatives (failing to predict instability) is high. The Decision Tree model, with higher overall metrics, is more reliable for this task, reducing the likelihood of missing an unstable condition.\n",
    "  \n",
    "- **Interpretability**: Decision Trees are also more interpretable than KNN, which might be crucial when explaining the decision process to engineers or stakeholders responsible for grid management. This makes the Decision Tree not only the better-performing model but also a more practical choice for this application.\n",
    "\n",
    "**In conclusion**, hyper-parameter tuning was critical in refining both models to achieve the best possible performance for this specific task. The selection of the Decision Tree model over the KNN model is justified not only by its superior metrics but also by its practical benefits in a real-world context where interpretability and minimizing critical errors are paramount.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32f82ac-4f42-43b8-97fb-09f21583a5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
